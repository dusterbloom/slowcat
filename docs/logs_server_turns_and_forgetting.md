2025-08-19 23:53:13.786 | DEBUG    | kokoro_tts:run_tts:406 - KokoroTTSService#1: Finished TTS [Would you like me to provide more details about that chapter?]
2025-08-19 23:53:13.786 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_processing_metrics:152 - KokoroTTSService#1 processing time: 0.38026905059814453
2025-08-19 23:53:23.652 | DEBUG    | pipecat.transports.base_output:_bot_stopped_speaking:584 - Bot stopped speaking
2025-08-19 23:53:25.223 | DEBUG    | pipecat.transports.base_input:_handle_user_interruption:348 - User started speaking
2025-08-19 23:53:25.224 | DEBUG    | processors.enhanced_stateless_memory:_safe_process_frame:237 - Speaker started: default_user
2025-08-19 23:53:25.226 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_ttfb_metrics:131 - SherpaOnlineSTTService#1 TTFB: 14.907062768936157
2025-08-19 23:53:25.226 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_processing_metrics:152 - SherpaOnlineSTTService#1 processing time: 14.907173871994019
2025-08-19 23:53:26.888 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'In our third'
2025-08-19 23:53:26.942 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'In our third'
2025-08-19 23:53:27.042 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'In our third'
2025-08-19 23:53:27.142 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'In our third'
2025-08-19 23:53:27.242 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'In our third'
2025-08-19 23:53:27.342 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'In our third'
2025-08-19 23:53:27.442 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'In our third'
2025-08-19 23:53:27.541 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'In our third'
2025-08-19 23:53:27.642 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'In our third'
2025-08-19 23:53:27.742 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'In our third'
2025-08-19 23:53:27.842 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'In our third'
2025-08-19 23:53:27.942 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'In our third'
2025-08-19 23:53:28.086 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'In our third Corondoyle's book'
2025-08-19 23:53:28.141 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'In our third Corondoyle's book'
2025-08-19 23:53:28.242 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'In our third Corondoyle's book'
2025-08-19 23:53:28.342 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'In our third Corondoyle's book'
2025-08-19 23:53:28.442 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'In our third Corondoyle's book'
2025-08-19 23:53:28.542 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'In our third Corondoyle's book'
2025-08-19 23:53:28.642 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'In our third Corondoyle's book'
2025-08-19 23:53:28.960 | DEBUG    | pipecat.audio.turn.smart_turn.base_smart_turn:analyze_end_of_turn:157 - End of Turn result: EndOfTurnState.COMPLETE
2025-08-19 23:53:28.961 | DEBUG    | pipecat.transports.base_input:_handle_user_interruption:372 - User stopped speaking
WARNING:asyncio:Executing <Task pending name='SmallWebRTCInputTransport#0::_audio_task_handler' coro=<TaskManager.create_task.<locals>.run_coroutine() running at /Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/pipecat/utils/asyncio/task_manager.py:236> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.10_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/queues.py:155> cb=[TaskManager._task_done_handler()] created at /Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/pipecat/utils/asyncio/task_manager.py:247> took 0.219 seconds
2025-08-19 23:53:28.963 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'In our third Corondoyle's book'
2025-08-19 23:53:28.990 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'In our third Corondoyle's book'
2025-08-19 23:53:29.007 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'In our third Corondoyle's book'
2025-08-19 23:53:29.042 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'In our third Corondoyle's book'
2025-08-19 23:53:29.142 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'In our third Corondoyle's book'
2025-08-19 23:53:29.242 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'In our third Corondoyle's book'
2025-08-19 23:53:29.388 | DEBUG    | services.sherpa_streaming_stt_v2:_add_punctuation:295 - Punctuation: 'In our third Corondoyle's book, are you sure' -> 'In our third Corondoyle's book ,,are you sure?'
2025-08-19 23:53:29.388 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:368 - 🎯 Sherpa endpoint text: 'In our third Corondoyle's book ,,are you sure?' (endpoint detected)
2025-08-19 23:53:29.388 | INFO     | services.sherpa_streaming_stt_v2:run_stt:551 - ✅ Sherpa final: 'In our third Corondoyle's book, are you sure?' (endpoint detected)
2025-08-19 23:53:29.389 | INFO     | processors.enhanced_stateless_memory:_safe_process_frame:244 - 🧠 ENHANCED: Captured user message: In our third Corondoyle's book, are you sure?...
2025-08-19 23:53:29.390 | INFO     | processors.enhanced_stateless_memory:_store_user_message_immediately:311 - 🧠 ENHANCED: 💾 Persisted to LMDB warm tier
2025-08-19 23:53:29.390 | INFO     | processors.enhanced_stateless_memory:_store_user_message_immediately:316 - 🧠 ENHANCED: ✅ Stored user message immediately: 'In our third Corondoyle's book...'
2025-08-19 23:53:29.390 | INFO     | processors.enhanced_stateless_memory:_store_user_message_immediately:317 - 🧠 ENHANCED: Hot tier now has 10 items
2025-08-19 23:53:29.397 | DEBUG    | processors.smart_context_manager:process_frame:120 - 🎤 Processing transcription: 'In our third Corondoyle's book, are you sure?...'
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
2025-08-19 23:53:29.455 | DEBUG    | memory.query_router:route_query:276 - 🎯 Query classified: personal (0.21) - 'In our third Corondoyle's book, are you sure?...'
2025-08-19 23:53:29.455 | DEBUG    | memory.spacy_fact_extractor:extract_facts:80 - 🔍 Extracting facts from: 'In our third Corondoyle's book, are you sure?...'
2025-08-19 23:53:29.490 | DEBUG    | memory.spacy_fact_extractor:extract_facts:111 - ✨ Extracted 0 unique facts
2025-08-19 23:53:29.490 | DEBUG    | memory.spacy_fact_extractor:extract_facts_from_text:692 - 🧠 spaCy extracted 0 facts from text
2025-08-19 23:53:29.490 | DEBUG    | memory.facts_graph:extract_facts_from_text:480 - 🔍 spaCy extracted 0 facts from text
2025-08-19 23:53:29.491 | DEBUG    | processors.smart_context_manager:_extract_facts_async:491 - 🔍 Extracted and stored 0 facts from: 'In our third Corondoyle's book...'
2025-08-19 23:53:29.493 | INFO     | memory.query_router:route_query:298 - 🔍 Query routed: 1 results in 48.6ms using hybrid strategy
2025-08-19 23:53:29.493 | DEBUG    | processors.smart_context_manager:_build_recent_context:478 - 📝 Recent context: 2 exchanges, 17 tokens
2025-08-19 23:53:29.493 | INFO     | processors.smart_context_manager:_build_fixed_context:244 - 🧠 Built fixed context: 366/4096 tokens (95.2ms)
2025-08-19 23:53:29.494 | DEBUG    | processors.smart_context_manager:_build_fixed_context:246 -    System: 234, Facts: 47, Recent: 72, Current: 13
<string>:4: DeprecationWarning: LLMMessagesFrame is deprecated and will be removed in a future version. Instead, use either `LLMMessagesUpdateFrame` with `run_llm=True`, or `OpenAILLMContextFrame` with desired messages in a new context
2025-08-19 23:53:29.495 | DEBUG    | pipecat.services.openai.base_llm:_stream_chat_completions:211 - DedupOpenAILLMService#1: Generating chat [[{"role": "system", "content": "You are Slowcat, a helpful AI assistant.\nTime: 2025-08-19 23:53:29\n\n[Session Info]\nTurn: 11\nDuration: 2m 53s\nSpeaker: default_user\nSessions: 0\n\n[Tone Guidance]\nRelationship: first-time\n- First-time: be welcoming, explain briefly when asked, avoid assumptions.\n- Returning: be concise and slightly familiar; reuse known facts.\n- Long-term: be efficient and comfortable; prioritize direct answers.\n\n[Session Info]\nTurn: 11\nDuration: 2m 53s\nSpeaker: default_user\nSessions: 0\n\n[Memory Instructions]\n- The following facts are about the user (the person you are talking to), NOT about you.\n- Never present user facts as your own attributes; do not say \"I'm ...\" for the user's info.\n- When answering about the user, use second person (\"you\") or neutral phrasing.\n- Be concise. If a direct answer is clear, avoid greetings and extra fluff.\n- If you need to recall something specific that is not provided, ask a short clarification question.\n\n[Relevant Facts — about the user (use 'you' when answering; do not claim as yours)]\n- user's name_name is Peppy\n- user's dog_name is Potola\n- user's age is 45"}, {"role": "assistant", "content": "about"}, {"role": "assistant", "content": "that"}, {"role": "assistant", "content": "chapter"}, {"role": "assistant", "content": "?"}, {"role": "user", "content": "In our third Corondoyle's book, are you sure?"}, {"role": "user", "content": "In our third Corondoyle's book, are you sure?"}]]
2025-08-19 23:53:30.166 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_ttfb_metrics:131 - DedupOpenAILLMService#1 TTFB: 0.6707320213317871
2025-08-19 23:53:30.262 | INFO     | kokoro_tts:run_tts:274 - ✅ TTS text already clean: 'Yes, I'm sure....'
2025-08-19 23:53:30.262 | DEBUG    | kokoro_tts:run_tts:279 - KokoroTTSService#1: Generating TTS [Yes, I'm sure.]
2025-08-19 23:53:30.262 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:start_tts_usage_metrics:191 - KokoroTTSService#1 usage characters: 14
2025-08-19 23:53:30.262 | DEBUG    | kokoro_tts:_generate_audio_streaming:190 - Starting streaming audio generation for: Yes, I'm sure.
2025-08-19 23:53:30.831 | DEBUG    | kokoro_tts:_generate_audio_streaming:216 - Generated audio chunk 1
2025-08-19 23:53:30.840 | DEBUG    | kokoro_tts:_generate_audio_streaming:224 - Streaming generation complete, generated 1 chunks
2025-08-19 23:53:30.843 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_ttfb_metrics:131 - KokoroTTSService#1 TTFB: 0.5812032222747803
2025-08-19 23:53:30.846 | DEBUG    | pipecat.transports.base_output:_bot_started_speaking:568 - Bot started speaking
2025-08-19 23:53:30.854 | DEBUG    | kokoro_tts:run_tts:406 - KokoroTTSService#1: Finished TTS [Yes, I'm sure.]
2025-08-19 23:53:30.854 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_processing_metrics:152 - KokoroTTSService#1 processing time: 0.592167854309082
2025-08-19 23:53:31.495 | WARNING  | kokoro_tts:run_tts:272 - 🧹 TTS SANITIZATION: ' The book is titled *The Third Corondoyle*, and it...' -> 'The book is titled The Third Corondoyle, and it's ...'
2025-08-19 23:53:31.495 | DEBUG    | kokoro_tts:run_tts:279 - KokoroTTSService#1: Generating TTS [The book is titled The Third Corondoyle, and it's a fictional work that explores themes of adventure and mystery.]
2025-08-19 23:53:31.495 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:start_tts_usage_metrics:191 - KokoroTTSService#1 usage characters: 113
2025-08-19 23:53:31.495 | DEBUG    | kokoro_tts:_generate_audio_streaming:190 - Starting streaming audio generation for: The book is titled The Third Corondoyle, and it's a fictional work that explores themes of adventure and mystery.
2025-08-19 23:53:31.986 | DEBUG    | services.sherpa_streaming_stt_v2:_add_punctuation:295 - Punctuation: '?' -> '?.'
2025-08-19 23:53:31.986 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:368 - 🎯 Sherpa endpoint text: '?.' (endpoint detected)
2025-08-19 23:53:31.986 | DEBUG    | services.sherpa_streaming_stt_v2:run_stt:523 - ⏳ Holding short endpoint '' (0 words) for 350ms
2025-08-19 23:53:32.045 | DEBUG    | services.sherpa_streaming_stt_v2:_add_punctuation:295 - Punctuation: '?' -> '?.'
2025-08-19 23:53:32.045 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:368 - 🎯 Sherpa endpoint text: '?.' (endpoint detected)
2025-08-19 23:53:32.142 | DEBUG    | services.sherpa_streaming_stt_v2:_add_punctuation:295 - Punctuation: '?' -> '?.'
2025-08-19 23:53:32.142 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:368 - 🎯 Sherpa endpoint text: '?.' (endpoint detected)
2025-08-19 23:53:32.231 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:start_llm_usage_metrics:173 - DedupOpenAILLMService#1 prompt tokens: 348, completion tokens: 47
2025-08-19 23:53:32.233 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_processing_metrics:152 - DedupOpenAILLMService#1 processing time: 2.7374398708343506
2025-08-19 23:53:32.246 | DEBUG    | services.sherpa_streaming_stt_v2:_add_punctuation:295 - Punctuation: '?' -> '?.'
2025-08-19 23:53:32.246 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:368 - 🎯 Sherpa endpoint text: '?.' (endpoint detected)
2025-08-19 23:53:32.343 | DEBUG    | services.sherpa_streaming_stt_v2:_add_punctuation:295 - Punctuation: '?' -> '?.'
2025-08-19 23:53:32.343 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:368 - 🎯 Sherpa endpoint text: '?.' (endpoint detected)
2025-08-19 23:53:32.343 | INFO     | services.sherpa_streaming_stt_v2:run_stt:529 - ✅ Sherpa final (debounced): ''
2025-08-19 23:53:32.344 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_ttfb_metrics:131 - SherpaOnlineSTTService#1 TTFB: 2.8387770652770996
2025-08-19 23:53:32.344 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_processing_metrics:152 - SherpaOnlineSTTService#1 processing time: 2.838855028152466
2025-08-19 23:53:32.567 | DEBUG    | kokoro_tts:_generate_audio_streaming:216 - Generated audio chunk 1
2025-08-19 23:53:32.580 | DEBUG    | kokoro_tts:_generate_audio_streaming:224 - Streaming generation complete, generated 1 chunks
2025-08-19 23:53:32.580 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_ttfb_metrics:131 - KokoroTTSService#1 TTFB: 1.0851490497589111
2025-08-19 23:53:32.597 | DEBUG    | kokoro_tts:run_tts:406 - KokoroTTSService#1: Finished TTS [The book is titled The Third Corondoyle, and it's a fictional work that explores themes of adventure and mystery.]
2025-08-19 23:53:32.597 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_processing_metrics:152 - KokoroTTSService#1 processing time: 1.102496862411499
2025-08-19 23:53:32.598 | WARNING  | kokoro_tts:run_tts:272 - 🧹 TTS SANITIZATION: ' If you have any specific questions about the book...' -> 'If you have any specific questions about the book,...'
2025-08-19 23:53:32.598 | DEBUG    | kokoro_tts:run_tts:279 - KokoroTTSService#1: Generating TTS [If you have any specific questions about the book, feel free to ask!]
2025-08-19 23:53:32.598 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:start_tts_usage_metrics:191 - KokoroTTSService#1 usage characters: 68
2025-08-19 23:53:32.598 | DEBUG    | kokoro_tts:_generate_audio_streaming:190 - Starting streaming audio generation for: If you have any specific questions about the book, feel free to ask!
2025-08-19 23:53:32.993 | DEBUG    | kokoro_tts:_generate_audio_streaming:216 - Generated audio chunk 1
2025-08-19 23:53:33.004 | DEBUG    | kokoro_tts:_generate_audio_streaming:224 - Streaming generation complete, generated 1 chunks
2025-08-19 23:53:33.005 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_ttfb_metrics:131 - KokoroTTSService#1 TTFB: 0.40677309036254883
2025-08-19 23:53:33.016 | DEBUG    | kokoro_tts:run_tts:406 - KokoroTTSService#1: Finished TTS [If you have any specific questions about the book, feel free to ask!]
2025-08-19 23:53:33.016 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_processing_metrics:152 - KokoroTTSService#1 processing time: 0.41817212104797363
2025-08-19 23:53:43.840 | DEBUG    | pipecat.transports.base_output:_bot_stopped_speaking:584 - Bot stopped speaking
2025-08-19 23:53:48.283 | DEBUG    | pipecat.transports.base_input:_handle_user_interruption:348 - User started speaking
2025-08-19 23:53:48.284 | DEBUG    | processors.enhanced_stateless_memory:_safe_process_frame:237 - Speaker started: default_user
2025-08-19 23:53:48.286 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_ttfb_metrics:131 - SherpaOnlineSTTService#1 TTFB: 15.843045949935913
2025-08-19 23:53:48.287 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_processing_metrics:152 - SherpaOnlineSTTService#1 processing time: 15.843153953552246
2025-08-19 23:53:49.890 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'What about what'
2025-08-19 23:53:49.942 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'What about what'
2025-08-19 23:53:50.042 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'What about what'
2025-08-19 23:53:50.142 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'What about what'
2025-08-19 23:53:50.243 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'What about what'
2025-08-19 23:53:50.343 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'What about what'
2025-08-19 23:53:50.443 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'What about what'
2025-08-19 23:53:50.543 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'What about what'
2025-08-19 23:53:50.643 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'What about what'
2025-08-19 23:53:50.743 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'What about what'
2025-08-19 23:53:50.843 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'What about what'
2025-08-19 23:53:50.943 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'What about what'
2025-08-19 23:53:51.043 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'What about what'
2025-08-19 23:53:51.360 | DEBUG    | pipecat.audio.turn.smart_turn.base_smart_turn:analyze_end_of_turn:157 - End of Turn result: EndOfTurnState.COMPLETE
2025-08-19 23:53:51.360 | DEBUG    | pipecat.transports.base_input:_handle_user_interruption:372 - User stopped speaking
WARNING:asyncio:Executing <Task pending name='SmallWebRTCInputTransport#0::_audio_task_handler' coro=<TaskManager.create_task.<locals>.run_coroutine() running at /Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/pipecat/utils/asyncio/task_manager.py:236> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.10_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/queues.py:155> cb=[TaskManager._task_done_handler()] created at /Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/pipecat/utils/asyncio/task_manager.py:247> took 0.218 seconds
2025-08-19 23:53:51.407 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'What about what about your creators'
2025-08-19 23:53:51.423 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'What about what about your creators'
2025-08-19 23:53:51.433 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'What about what about your creators'
2025-08-19 23:53:51.448 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'What about what about your creators'
2025-08-19 23:53:51.542 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'What about what about your creators'
2025-08-19 23:53:51.643 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'What about what about your creators'
2025-08-19 23:53:51.743 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'What about what about your creators'
2025-08-19 23:53:51.843 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'What about what about your creators'
2025-08-19 23:53:51.943 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'What about what about your creators'
2025-08-19 23:53:52.043 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'What about what about your creators'
2025-08-19 23:53:52.143 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'What about what about your creators'
2025-08-19 23:53:52.163 | DEBUG    | pipecat.transports.base_input:_handle_user_interruption:348 - User started speaking
2025-08-19 23:53:52.164 | DEBUG    | processors.enhanced_stateless_memory:_safe_process_frame:237 - Speaker started: default_user
2025-08-19 23:53:52.242 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'What about what about your creators'
2025-08-19 23:53:52.342 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: 'What about what about your creators'
2025-08-19 23:53:52.487 | DEBUG    | services.sherpa_streaming_stt_v2:_add_punctuation:295 - Punctuation: 'What about what about your creators' -> 'What about what about your creators?'
2025-08-19 23:53:52.487 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:368 - 🎯 Sherpa endpoint text: 'What about what about your creators?' (endpoint detected)
2025-08-19 23:53:52.487 | INFO     | services.sherpa_streaming_stt_v2:run_stt:551 - ✅ Sherpa final: 'What about what about your creators?' (endpoint detected)
2025-08-19 23:53:52.489 | INFO     | processors.enhanced_stateless_memory:_safe_process_frame:244 - 🧠 ENHANCED: Captured user message: What about what about your creators?...
2025-08-19 23:53:52.489 | INFO     | processors.enhanced_stateless_memory:_store_user_message_immediately:311 - 🧠 ENHANCED: 💾 Persisted to LMDB warm tier
2025-08-19 23:53:52.489 | INFO     | processors.enhanced_stateless_memory:_store_user_message_immediately:316 - 🧠 ENHANCED: ✅ Stored user message immediately: 'What about what about your cre...'
2025-08-19 23:53:52.489 | INFO     | processors.enhanced_stateless_memory:_store_user_message_immediately:317 - 🧠 ENHANCED: Hot tier now has 10 items
2025-08-19 23:53:52.497 | DEBUG    | processors.smart_context_manager:process_frame:120 - 🎤 Processing transcription: 'What about what about your creators?...'
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
2025-08-19 23:53:52.530 | DEBUG    | memory.query_router:route_query:276 - 🎯 Query classified: general (0.24) - 'What about what about your creators?...'
2025-08-19 23:53:52.530 | INFO     | memory.query_router:route_query:298 - 🔍 Query routed: 0 results in 12.9ms using bypass strategy
2025-08-19 23:53:52.530 | DEBUG    | processors.smart_context_manager:_build_recent_context:478 - 📝 Recent context: 2 exchanges, 11 tokens
2025-08-19 23:53:52.530 | INFO     | processors.smart_context_manager:_build_fixed_context:244 - 🧠 Built fixed context: 355/4096 tokens (31.5ms)
2025-08-19 23:53:52.530 | DEBUG    | processors.smart_context_manager:_build_fixed_context:246 -    System: 234, Facts: 47, Recent: 67, Current: 7
<string>:4: DeprecationWarning: LLMMessagesFrame is deprecated and will be removed in a future version. Instead, use either `LLMMessagesUpdateFrame` with `run_llm=True`, or `OpenAILLMContextFrame` with desired messages in a new context
2025-08-19 23:53:52.531 | DEBUG    | memory.spacy_fact_extractor:extract_facts:80 - 🔍 Extracting facts from: 'What about what about your creators?...'
2025-08-19 23:53:52.589 | DEBUG    | memory.spacy_fact_extractor:extract_facts:111 - ✨ Extracted 0 unique facts
2025-08-19 23:53:52.589 | DEBUG    | memory.spacy_fact_extractor:extract_facts_from_text:692 - 🧠 spaCy extracted 0 facts from text
2025-08-19 23:53:52.589 | DEBUG    | memory.facts_graph:extract_facts_from_text:480 - 🔍 spaCy extracted 0 facts from text
2025-08-19 23:53:52.589 | DEBUG    | processors.smart_context_manager:_extract_facts_async:491 - 🔍 Extracted and stored 0 facts from: 'What about what about your cre...'
2025-08-19 23:53:52.591 | DEBUG    | pipecat.services.openai.base_llm:_stream_chat_completions:211 - DedupOpenAILLMService#1: Generating chat [[{"role": "system", "content": "You are Slowcat, a helpful AI assistant.\nTime: 2025-08-19 23:53:52\n\n[Session Info]\nTurn: 12\nDuration: 3m 16s\nSpeaker: default_user\nSessions: 0\n\n[Tone Guidance]\nRelationship: first-time\n- First-time: be welcoming, explain briefly when asked, avoid assumptions.\n- Returning: be concise and slightly familiar; reuse known facts.\n- Long-term: be efficient and comfortable; prioritize direct answers.\n\n[Session Info]\nTurn: 12\nDuration: 3m 16s\nSpeaker: default_user\nSessions: 0\n\n[Memory Instructions]\n- The following facts are about the user (the person you are talking to), NOT about you.\n- Never present user facts as your own attributes; do not say \"I'm ...\" for the user's info.\n- When answering about the user, use second person (\"you\") or neutral phrasing.\n- Be concise. If a direct answer is clear, avoid greetings and extra fluff.\n- If you need to recall something specific that is not provided, ask a short clarification question.\n\n[Relevant Facts — about the user (use 'you' when answering; do not claim as yours)]\n- user's name_name is Peppy\n- user's dog_name is Potola\n- user's age is 45"}, {"role": "assistant", "content": "free"}, {"role": "assistant", "content": "to"}, {"role": "assistant", "content": "ask"}, {"role": "assistant", "content": "!"}, {"role": "user", "content": "What about what about your creators?"}, {"role": "user", "content": "What about what about your creators?"}]]
2025-08-19 23:53:53.599 | DEBUG    | pipecat.audio.turn.smart_turn.base_smart_turn:analyze_end_of_turn:157 - End of Turn result: EndOfTurnState.INCOMPLETE
WARNING:asyncio:Executing <Task pending name='SmallWebRTCInputTransport#0::_audio_task_handler' coro=<TaskManager.create_task.<locals>.run_coroutine() running at /Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/pipecat/utils/asyncio/task_manager.py:236> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.10_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/queues.py:155> cb=[TaskManager._task_done_handler()] created at /Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/pipecat/utils/asyncio/task_manager.py:247> took 0.438 seconds
2025-08-19 23:53:53.601 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_ttfb_metrics:131 - DedupOpenAILLMService#1 TTFB: 1.0104219913482666
2025-08-19 23:53:53.635 | INFO     | kokoro_tts:run_tts:274 - ✅ TTS text already clean: 'Ah, that's a great question!...'
2025-08-19 23:53:53.635 | DEBUG    | kokoro_tts:run_tts:279 - KokoroTTSService#1: Generating TTS [Ah, that's a great question!]
2025-08-19 23:53:53.635 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:start_tts_usage_metrics:191 - KokoroTTSService#1 usage characters: 28
2025-08-19 23:53:53.635 | DEBUG    | kokoro_tts:_generate_audio_streaming:190 - Starting streaming audio generation for: Ah, that's a great question!
2025-08-19 23:53:53.739 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: '? Who are they'
2025-08-19 23:53:53.759 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: '? Who are they'
2025-08-19 23:53:53.842 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: '? Who are they'
2025-08-19 23:53:53.942 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: '? Who are they'
2025-08-19 23:53:54.043 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: '? Who are they'
2025-08-19 23:53:54.143 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: '? Who are they'
2025-08-19 23:53:54.243 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: '? Who are they'
2025-08-19 23:53:54.306 | DEBUG    | kokoro_tts:_generate_audio_streaming:216 - Generated audio chunk 1
2025-08-19 23:53:54.318 | DEBUG    | kokoro_tts:_generate_audio_streaming:224 - Streaming generation complete, generated 1 chunks
2025-08-19 23:53:54.318 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_ttfb_metrics:131 - KokoroTTSService#1 TTFB: 0.6833047866821289
2025-08-19 23:53:54.320 | DEBUG    | pipecat.transports.base_output:_bot_started_speaking:568 - Bot started speaking
2025-08-19 23:53:54.329 | DEBUG    | kokoro_tts:run_tts:406 - KokoroTTSService#1: Finished TTS [Ah, that's a great question!]
2025-08-19 23:53:54.329 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_processing_metrics:152 - KokoroTTSService#1 processing time: 0.693882942199707
2025-08-19 23:53:54.344 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: '? Who are they'
2025-08-19 23:53:54.442 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: '? Who are they'
2025-08-19 23:53:54.542 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: '? Who are they'
2025-08-19 23:53:54.642 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: '? Who are they'
2025-08-19 23:53:54.742 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: '? Who are they'
2025-08-19 23:53:54.782 | WARNING  | kokoro_tts:run_tts:272 - 🧹 TTS SANITIZATION: ' I'm created by a team of brilliant engineers and ...' -> 'I'm created by a team of brilliant engineers and p...'
2025-08-19 23:53:54.782 | DEBUG    | kokoro_tts:run_tts:279 - KokoroTTSService#1: Generating TTS [I'm created by a team of brilliant engineers and programmers who are passionate about creating helpful and intelligent AI assistants.]
2025-08-19 23:53:54.782 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:start_tts_usage_metrics:191 - KokoroTTSService#1 usage characters: 133
2025-08-19 23:53:54.782 | DEBUG    | kokoro_tts:_generate_audio_streaming:190 - Starting streaming audio generation for: I'm created by a team of brilliant engineers and programmers who are passionate about creating helpful and intelligent AI assistants.
2025-08-19 23:53:54.842 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:370 - 🔄 Sherpa interim: '? Who are they'
2025-08-19 23:53:54.983 | DEBUG    | services.sherpa_streaming_stt_v2:_add_punctuation:295 - Punctuation: '? Who are they?' -> '? Who are they ??'
2025-08-19 23:53:54.983 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:368 - 🎯 Sherpa endpoint text: '? Who are they ??' (endpoint detected)
2025-08-19 23:53:54.983 | INFO     | services.sherpa_streaming_stt_v2:run_stt:551 - ✅ Sherpa final: 'Who are they?' (endpoint detected)
2025-08-19 23:53:54.983 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_ttfb_metrics:131 - SherpaOnlineSTTService#1 TTFB: 2.3794400691986084
2025-08-19 23:53:54.983 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_processing_metrics:152 - SherpaOnlineSTTService#1 processing time: 2.379518985748291
2025-08-19 23:53:54.986 | INFO     | processors.enhanced_stateless_memory:_safe_process_frame:244 - 🧠 ENHANCED: Captured user message: Who are they?...
2025-08-19 23:53:54.986 | INFO     | processors.enhanced_stateless_memory:_store_user_message_immediately:311 - 🧠 ENHANCED: 💾 Persisted to LMDB warm tier
2025-08-19 23:53:54.986 | INFO     | processors.enhanced_stateless_memory:_store_user_message_immediately:316 - 🧠 ENHANCED: ✅ Stored user message immediately: 'Who are they?...'
2025-08-19 23:53:54.986 | INFO     | processors.enhanced_stateless_memory:_store_user_message_immediately:317 - 🧠 ENHANCED: Hot tier now has 10 items
2025-08-19 23:53:55.002 | DEBUG    | processors.smart_context_manager:process_frame:120 - 🎤 Processing transcription: 'Who are they?...'
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
2025-08-19 23:53:55.128 | DEBUG    | memory.query_router:route_query:276 - 🎯 Query classified: general (0.09) - 'Who are they?...'
2025-08-19 23:53:55.128 | INFO     | memory.query_router:route_query:298 - 🔍 Query routed: 0 results in 17.8ms using bypass strategy
2025-08-19 23:53:55.128 | DEBUG    | processors.smart_context_manager:_build_recent_context:478 - 📝 Recent context: 2 exchanges, 10 tokens
2025-08-19 23:53:55.128 | INFO     | processors.smart_context_manager:_build_fixed_context:244 - 🧠 Built fixed context: 352/4096 tokens (124.6ms)
2025-08-19 23:53:55.128 | DEBUG    | processors.smart_context_manager:_build_fixed_context:246 -    System: 234, Facts: 47, Recent: 67, Current: 4
<string>:4: DeprecationWarning: LLMMessagesFrame is deprecated and will be removed in a future version. Instead, use either `LLMMessagesUpdateFrame` with `run_llm=True`, or `OpenAILLMContextFrame` with desired messages in a new context
WARNING:asyncio:Executing <Task pending name='SmartContextManager#0::__process_frame_task_handler' coro=<TaskManager.create_task.<locals>.run_coroutine() running at /Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/pipecat/utils/asyncio/task_manager.py:236> wait_for=<Future pending cb=[Task.task_wakeup()] created at /opt/homebrew/Cellar/python@3.12/3.12.10_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/queues.py:155> cb=[TaskManager._task_done_handler()] created at /Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/pipecat/utils/asyncio/task_manager.py:247> took 0.126 seconds
2025-08-19 23:53:55.129 | DEBUG    | memory.spacy_fact_extractor:extract_facts:80 - 🔍 Extracting facts from: 'Who are they?...'
2025-08-19 23:53:55.186 | DEBUG    | memory.spacy_fact_extractor:extract_facts:111 - ✨ Extracted 0 unique facts
2025-08-19 23:53:55.186 | DEBUG    | memory.spacy_fact_extractor:extract_facts_from_text:692 - 🧠 spaCy extracted 0 facts from text
2025-08-19 23:53:55.186 | DEBUG    | memory.facts_graph:extract_facts_from_text:480 - 🔍 spaCy extracted 0 facts from text
2025-08-19 23:53:55.186 | DEBUG    | processors.smart_context_manager:_extract_facts_async:491 - 🔍 Extracted and stored 0 facts from: 'Who are they?...'
2025-08-19 23:53:56.163 | DEBUG    | pipecat.audio.turn.smart_turn.base_smart_turn:append_audio:128 - End of Turn complete due to stop_secs. Silence in ms: 3000.0
2025-08-19 23:53:56.163 | DEBUG    | pipecat.transports.base_input:_handle_user_interruption:372 - User stopped speaking
2025-08-19 23:53:56.743 | DEBUG    | pipecat.transports.base_output:_bot_stopped_speaking:584 - Bot stopped speaking
2025-08-19 23:53:56.825 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:start_llm_usage_metrics:173 - DedupOpenAILLMService#1 prompt tokens: 336, completion tokens: 65
2025-08-19 23:53:56.828 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_processing_metrics:152 - DedupOpenAILLMService#1 processing time: 4.236967086791992
2025-08-19 23:53:56.828 | DEBUG    | pipecat.services.openai.base_llm:_stream_chat_completions:211 - DedupOpenAILLMService#1: Generating chat [[{"role": "system", "content": "You are Slowcat, a helpful AI assistant.\nTime: 2025-08-19 23:53:55\n\n[Session Info]\nTurn: 13\nDuration: 3m 18s\nSpeaker: default_user\nSessions: 0\n\n[Tone Guidance]\nRelationship: first-time\n- First-time: be welcoming, explain briefly when asked, avoid assumptions.\n- Returning: be concise and slightly familiar; reuse known facts.\n- Long-term: be efficient and comfortable; prioritize direct answers.\n\n[Session Info]\nTurn: 13\nDuration: 3m 18s\nSpeaker: default_user\nSessions: 0\n\n[Memory Instructions]\n- The following facts are about the user (the person you are talking to), NOT about you.\n- Never present user facts as your own attributes; do not say \"I'm ...\" for the user's info.\n- When answering about the user, use second person (\"you\") or neutral phrasing.\n- Be concise. If a direct answer is clear, avoid greetings and extra fluff.\n- If you need to recall something specific that is not provided, ask a short clarification question.\n\n[Relevant Facts — about the user (use 'you' when answering; do not claim as yours)]\n- user's name_name is Peppy\n- user's dog_name is Potola\n- user's age is 45"}, {"role": "assistant", "content": "They"}, {"role": "assistant", "content": "work"}, {"role": "assistant", "content": "tirelessly"}, {"role": "assistant", "content": "to"}, {"role": "user", "content": "Who are they?"}, {"role": "user", "content": "Who are they?"}]]
2025-08-19 23:53:56.966 | DEBUG    | kokoro_tts:_generate_audio_streaming:216 - Generated audio chunk 1
2025-08-19 23:53:56.988 | DEBUG    | kokoro_tts:_generate_audio_streaming:224 - Streaming generation complete, generated 1 chunks
2025-08-19 23:53:56.988 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_ttfb_metrics:131 - KokoroTTSService#1 TTFB: 2.2063732147216797
2025-08-19 23:53:56.990 | DEBUG    | pipecat.transports.base_output:_bot_started_speaking:568 - Bot started speaking
2025-08-19 23:53:57.014 | DEBUG    | kokoro_tts:run_tts:406 - KokoroTTSService#1: Finished TTS [I'm created by a team of brilliant engineers and programmers who are passionate about creating helpful and intelligent AI assistants.]
2025-08-19 23:53:57.014 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_processing_metrics:152 - KokoroTTSService#1 processing time: 2.2326467037200928
2025-08-19 23:53:57.015 | WARNING  | kokoro_tts:run_tts:272 - 🧹 TTS SANITIZATION: ' They work tirelessly to ensure that I can assist ...' -> 'They work tirelessly to ensure that I can assist y...'
2025-08-19 23:53:57.015 | DEBUG    | kokoro_tts:run_tts:279 - KokoroTTSService#1: Generating TTS [They work tirelessly to ensure that I can assist you in any way possible.]
2025-08-19 23:53:57.015 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:start_tts_usage_metrics:191 - KokoroTTSService#1 usage characters: 73
2025-08-19 23:53:57.015 | DEBUG    | kokoro_tts:_generate_audio_streaming:190 - Starting streaming audio generation for: They work tirelessly to ensure that I can assist you in any way possible.
2025-08-19 23:53:57.586 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_ttfb_metrics:131 - DedupOpenAILLMService#1 TTFB: 0.7571163177490234
2025-08-19 23:53:58.283 | DEBUG    | kokoro_tts:_generate_audio_streaming:216 - Generated audio chunk 1
2025-08-19 23:53:58.299 | DEBUG    | kokoro_tts:_generate_audio_streaming:224 - Streaming generation complete, generated 1 chunks
2025-08-19 23:53:58.305 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_ttfb_metrics:131 - KokoroTTSService#1 TTFB: 1.2902331352233887
2025-08-19 23:53:58.329 | DEBUG    | kokoro_tts:run_tts:406 - KokoroTTSService#1: Finished TTS [They work tirelessly to ensure that I can assist you in any way possible.]
2025-08-19 23:53:58.329 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_processing_metrics:152 - KokoroTTSService#1 processing time: 1.3146531581878662
2025-08-19 23:53:58.330 | WARNING  | kokoro_tts:run_tts:272 - 🧹 TTS SANITIZATION: ' Would you like me to tell you more about how I wa...' -> 'Would you like me to tell you more about how I was...'
2025-08-19 23:53:58.330 | DEBUG    | kokoro_tts:run_tts:279 - KokoroTTSService#1: Generating TTS [Would you like me to tell you more about how I was created or what my capabilities are?]
2025-08-19 23:53:58.330 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:start_tts_usage_metrics:191 - KokoroTTSService#1 usage characters: 87
2025-08-19 23:53:58.330 | DEBUG    | kokoro_tts:_generate_audio_streaming:190 - Starting streaming audio generation for: Would you like me to tell you more about how I was created or what my capabilities are?
2025-08-19 23:53:58.584 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:start_llm_usage_metrics:173 - DedupOpenAILLMService#1 prompt tokens: 332, completion tokens: 23
2025-08-19 23:53:58.586 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_processing_metrics:152 - DedupOpenAILLMService#1 processing time: 1.7578680515289307
2025-08-19 23:53:58.936 | DEBUG    | kokoro_tts:_generate_audio_streaming:216 - Generated audio chunk 1
2025-08-19 23:53:58.948 | DEBUG    | kokoro_tts:_generate_audio_streaming:224 - Streaming generation complete, generated 1 chunks
2025-08-19 23:53:58.948 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_ttfb_metrics:131 - KokoroTTSService#1 TTFB: 0.6184232234954834
2025-08-19 23:53:58.963 | DEBUG    | kokoro_tts:run_tts:406 - KokoroTTSService#1: Finished TTS [Would you like me to tell you more about how I was created or what my capabilities are?]
2025-08-19 23:53:58.963 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_processing_metrics:152 - KokoroTTSService#1 processing time: 0.6330461502075195
2025-08-19 23:53:58.963 | INFO     | kokoro_tts:run_tts:274 - ✅ TTS text already clean: 'You are Peppy, and I am Slowcat....'
2025-08-19 23:53:58.963 | DEBUG    | kokoro_tts:run_tts:279 - KokoroTTSService#1: Generating TTS [You are Peppy, and I am Slowcat.]
2025-08-19 23:53:58.963 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:start_tts_usage_metrics:191 - KokoroTTSService#1 usage characters: 32
2025-08-19 23:53:58.963 | DEBUG    | kokoro_tts:_generate_audio_streaming:190 - Starting streaming audio generation for: You are Peppy, and I am Slowcat.
2025-08-19 23:53:59.192 | DEBUG    | kokoro_tts:_generate_audio_streaming:216 - Generated audio chunk 1
2025-08-19 23:53:59.201 | DEBUG    | kokoro_tts:_generate_audio_streaming:224 - Streaming generation complete, generated 1 chunks
2025-08-19 23:53:59.201 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_ttfb_metrics:131 - KokoroTTSService#1 TTFB: 0.23777198791503906
2025-08-19 23:53:59.208 | DEBUG    | kokoro_tts:run_tts:406 - KokoroTTSService#1: Finished TTS [You are Peppy, and I am Slowcat.]
2025-08-19 23:53:59.208 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_processing_metrics:152 - KokoroTTSService#1 processing time: 0.2446751594543457
2025-08-19 23:53:59.208 | WARNING  | kokoro_tts:run_tts:272 - 🧹 TTS SANITIZATION: ' We are here to help you with anything you need....' -> 'We are here to help you with anything you need....'
2025-08-19 23:53:59.208 | DEBUG    | kokoro_tts:run_tts:279 - KokoroTTSService#1: Generating TTS [We are here to help you with anything you need.]
2025-08-19 23:53:59.208 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:start_tts_usage_metrics:191 - KokoroTTSService#1 usage characters: 47
2025-08-19 23:53:59.208 | DEBUG    | kokoro_tts:_generate_audio_streaming:190 - Starting streaming audio generation for: We are here to help you with anything you need.
2025-08-19 23:53:59.477 | DEBUG    | kokoro_tts:_generate_audio_streaming:216 - Generated audio chunk 1
2025-08-19 23:53:59.487 | DEBUG    | kokoro_tts:_generate_audio_streaming:224 - Streaming generation complete, generated 1 chunks
2025-08-19 23:53:59.488 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_ttfb_metrics:131 - KokoroTTSService#1 TTFB: 0.279862642288208
2025-08-19 23:53:59.496 | DEBUG    | kokoro_tts:run_tts:406 - KokoroTTSService#1: Finished TTS [We are here to help you with anything you need.]
2025-08-19 23:53:59.496 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_processing_metrics:152 - KokoroTTSService#1 processing time: 0.28781890869140625
2025-08-19 23:54:14.189 | DEBUG    | services.sherpa_streaming_stt_v2:_add_punctuation:295 - Punctuation: 'What' -> 'What?'
2025-08-19 23:54:14.189 | DEBUG    | services.sherpa_streaming_stt_v2:_process_audio_chunk:368 - 🎯 Sherpa endpoint text: 'What?' (endpoint detected)
2025-08-19 23:54:14.189 | INFO     | services.sherpa_streaming_stt_v2:run_stt:551 - ✅ Sherpa final: 'What?' (endpoint detected)
2025-08-19 23:54:14.190 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_ttfb_metrics:131 - SherpaOnlineSTTService#1 TTFB: 18.984586000442505
2025-08-19 23:54:14.190 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_processing_metrics:152 - SherpaOnlineSTTService#1 processing time: 18.98467206954956
2025-08-19 23:54:14.191 | INFO     | processors.enhanced_stateless_memory:_safe_process_frame:244 - 🧠 ENHANCED: Captured user message: What?...
2025-08-19 23:54:14.192 | INFO     | processors.enhanced_stateless_memory:_store_user_message_immediately:311 - 🧠 ENHANCED: 💾 Persisted to LMDB warm tier
2025-08-19 23:54:14.192 | INFO     | processors.enhanced_stateless_memory:_store_user_message_immediately:316 - 🧠 ENHANCED: ✅ Stored user message immediately: 'What?...'
2025-08-19 23:54:14.192 | INFO     | processors.enhanced_stateless_memory:_store_user_message_immediately:317 - 🧠 ENHANCED: Hot tier now has 10 items
2025-08-19 23:54:14.203 | DEBUG    | processors.smart_context_manager:process_frame:120 - 🎤 Processing transcription: 'What?...'
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul
  ret = a @ b
/Users/peppi/Dev/macos-local-voice-agents/server/.venv/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul
  ret = a @ b
2025-08-19 23:54:14.299 | DEBUG    | memory.query_router:route_query:276 - 🎯 Query classified: episodic (0.10) - 'What?...'
2025-08-19 23:54:14.300 | DEBUG    | memory.spacy_fact_extractor:extract_facts:80 - 🔍 Extracting facts from: 'What?...'
2025-08-19 23:54:14.350 | DEBUG    | memory.spacy_fact_extractor:extract_facts:111 - ✨ Extracted 0 unique facts
2025-08-19 23:54:14.350 | DEBUG    | memory.spacy_fact_extractor:extract_facts_from_text:692 - 🧠 spaCy extracted 0 facts from text
2025-08-19 23:54:14.350 | DEBUG    | memory.facts_graph:extract_facts_from_text:480 - 🔍 spaCy extracted 0 facts from text
2025-08-19 23:54:14.350 | DEBUG    | processors.smart_context_manager:_extract_facts_async:491 - 🔍 Extracted and stored 0 facts from: 'What?...'
2025-08-19 23:54:14.353 | INFO     | memory.query_router:route_query:298 - 🔍 Query routed: 2 results in 63.8ms using hybrid strategy
2025-08-19 23:54:14.353 | DEBUG    | processors.smart_context_manager:_build_recent_context:478 - 📝 Recent context: 2 exchanges, 6 tokens
2025-08-19 23:54:14.353 | INFO     | processors.smart_context_manager:_build_fixed_context:244 - 🧠 Built fixed context: 345/4096 tokens (149.2ms)
2025-08-19 23:54:14.353 | DEBUG    | processors.smart_context_manager:_build_fixed_context:246 -    System: 234, Facts: 47, Recent: 62, Current: 2
<string>:4: DeprecationWarning: LLMMessagesFrame is deprecated and will be removed in a future version. Instead, use either `LLMMessagesUpdateFrame` with `run_llm=True`, or `OpenAILLMContextFrame` with desired messages in a new context
2025-08-19 23:54:14.355 | DEBUG    | pipecat.services.openai.base_llm:_stream_chat_completions:211 - DedupOpenAILLMService#1: Generating chat [[{"role": "system", "content": "You are Slowcat, a helpful AI assistant.\nTime: 2025-08-19 23:54:14\n\n[Session Info]\nTurn: 14\nDuration: 3m 38s\nSpeaker: default_user\nSessions: 0\n\n[Tone Guidance]\nRelationship: first-time\n- First-time: be welcoming, explain briefly when asked, avoid assumptions.\n- Returning: be concise and slightly familiar; reuse known facts.\n- Long-term: be efficient and comfortable; prioritize direct answers.\n\n[Session Info]\nTurn: 14\nDuration: 3m 38s\nSpeaker: default_user\nSessions: 0\n\n[Memory Instructions]\n- The following facts are about the user (the person you are talking to), NOT about you.\n- Never present user facts as your own attributes; do not say \"I'm ...\" for the user's info.\n- When answering about the user, use second person (\"you\") or neutral phrasing.\n- Be concise. If a direct answer is clear, avoid greetings and extra fluff.\n- If you need to recall something specific that is not provided, ask a short clarification question.\n\n[Relevant Facts — about the user (use 'you' when answering; do not claim as yours)]\n- user's name_name is Peppy\n- user's dog_name is Potola\n- user's age is 45"}, {"role": "assistant", "content": "anything"}, {"role": "assistant", "content": "you"}, {"role": "assistant", "content": "need"}, {"role": "assistant", "content": "."}, {"role": "user", "content": "What?"}, {"role": "user", "content": "What?"}]]
2025-08-19 23:54:14.902 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_ttfb_metrics:131 - DedupOpenAILLMService#1 TTFB: 0.5463430881500244
2025-08-19 23:54:15.037 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:start_llm_usage_metrics:173 - DedupOpenAILLMService#1 prompt tokens: 326, completion tokens: 7
2025-08-19 23:54:15.039 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_processing_metrics:152 - DedupOpenAILLMService#1 processing time: 0.6837520599365234
2025-08-19 23:54:15.045 | INFO     | kokoro_tts:run_tts:274 - ✅ TTS text already clean: 'What are you looking for?...'
2025-08-19 23:54:15.045 | DEBUG    | kokoro_tts:run_tts:279 - KokoroTTSService#1: Generating TTS [What are you looking for?]
2025-08-19 23:54:15.045 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:start_tts_usage_metrics:191 - KokoroTTSService#1 usage characters: 25
2025-08-19 23:54:15.046 | DEBUG    | kokoro_tts:_generate_audio_streaming:190 - Starting streaming audio generation for: What are you looking for?
2025-08-19 23:54:15.240 | DEBUG    | kokoro_tts:_generate_audio_streaming:216 - Generated audio chunk 1
2025-08-19 23:54:15.247 | DEBUG    | kokoro_tts:_generate_audio_streaming:224 - Streaming generation complete, generated 1 chunks
2025-08-19 23:54:15.249 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_ttfb_metrics:131 - KokoroTTSService#1 TTFB: 0.2033228874206543
2025-08-19 23:54:15.254 | DEBUG    | kokoro_tts:run_tts:406 - KokoroTTSService#1: Finished TTS [What are you looking for?]
2025-08-19 23:54:15.254 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_processing_metrics:152 - KokoroTTSService#1 processing time: 0.2093350887298584
2025-08-19 23:54:17.985 | DEBUG    | pipecat.transports.network.webrtc_connection:_handle_signalling_message:550 - Signalling message received: {'type': 'trackStatus', 'receiver_index': 0, 'enabled': False}
2025-08-19 23:54:22.653 | DEBUG    | pipecat.transports.base_output:_bot_stopped_speaking:584 - Bot stopped speaking
2025-08-19 23:55:36.218 | DEBUG    | processors.enhanced_stateless_memory:_perform_degradation:677 - 🔄 Starting memory degradation cycle...
2025-08-19 23:55:36.218 | DEBUG    | processors.enhanced_stateless_memory:_degrade_hot_to_warm:755 - 🌡️ Degraded 5 items to warm tier (LZ4 compressed)
2025-08-19 23:55:36.219 | DEBUG    | processors.enhanced_stateless_memory:_degrade_warm_to_cold:831 - 🧊 Degraded 0 items to cold tier (Zstd compressed)
2025-08-19 23:55:36.219 | DEBUG    | processors.enhanced_stateless_memory:_compress_cold_tier:841 - 🗜️ Cold tier compression (placeholder for future summarization)
2025-08-19 23:55:36.219 | INFO     | processors.enhanced_stateless_memory:_perform_degradation:699 - ✅ Memory degradation cycle completed